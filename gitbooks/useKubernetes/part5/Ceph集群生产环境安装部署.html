
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>5.1. Ceph部署篇 · Kubernetes生态圈使用</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="ywq">
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-anchors/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="cephfs调优-性能测试-监控-常用命令.html" />
    
    
    <link rel="prev" href="./" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        <li class="header">Part 1-写在前面</li>
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    1. 总览篇
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Part 2-集群相关</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="../part2/">
            
                <a href="../part2/">
            
                    
                    2. 集群相关
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1.1" data-path="../part2/v1.9.0高可用集群本地离线部署记录.html">
            
                <a href="../part2/v1.9.0高可用集群本地离线部署记录.html">
            
                    
                    2.1. v1.9.0高可用集群部署
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.2" data-path="../part2/v1.14多master集群部署.html">
            
                <a href="../part2/v1.14多master集群部署.html">
            
                    
                    2.2. v1.14.3高可用集群部署
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.3" data-path="../part2/Kubernetes中的Pause容器.html">
            
                <a href="../part2/Kubernetes中的Pause容器.html">
            
                    
                    2.3. Kubernetes中的Pause容器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.4" data-path="../part2/RBAC权限控制.html">
            
                <a href="../part2/RBAC权限控制.html">
            
                    
                    2.4. RBAC权限控制
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.5" data-path="../part2/docker-k8s常用命令速查及rest-api.html">
            
                <a href="../part2/docker-k8s常用命令速查及rest-api.html">
            
                    
                    2.5. 常用命令与rest-api速查
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.6" data-path="../part2/Kubernetes各组件参数配置优化建议.html">
            
                <a href="../part2/Kubernetes各组件参数配置优化建议.html">
            
                    
                    2.6. Kubernetes各组件参数配置优化建议
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">Part 3-网络与服务</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="../part3/">
            
                <a href="../part3/">
            
                    
                    3. 网络与服务
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.1" data-path="../part3/Traefik提供ingress-http服务.html">
            
                <a href="../part3/Traefik提供ingress-http服务.html">
            
                    
                    3.1. Traefik 提供ingress http服务
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.2" data-path="../part3/kube-router提供BGP全直通网络.html">
            
                <a href="../part3/kube-router提供BGP全直通网络.html">
            
                    
                    3.2. Kube-router BGP全直通网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.3" data-path="../part3/kube-router工作模式抓包分析.html">
            
                <a href="../part3/kube-router工作模式抓包分析.html">
            
                    
                    3.3. Kube-router ipvs Service模式抓包分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.4" data-path="../part3/VXLAN和Flannel.html">
            
                <a href="../part3/VXLAN和Flannel.html">
            
                    
                    3.4. VXLAN和Flannel
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">Part 4-监控</li>
        
        
    
        <li class="chapter " data-level="4.1" data-path="../part4/">
            
                <a href="../part4/">
            
                    
                    4. Prometheus监控
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1.1" data-path="../part4/监控--Prometheus部署篇.html">
            
                <a href="../part4/监控--Prometheus部署篇.html">
            
                    
                    4.1. Prometheus部署篇
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.1.2" data-path="../part4/监控--Prometheus扩展篇（mysqld-exporter、服务发现、监控项、联邦、relabel）.html">
            
                <a href="../part4/监控--Prometheus扩展篇（mysqld-exporter、服务发现、监控项、联邦、relabel）.html">
            
                    
                    4.2. Prometheus扩展篇
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.1.3" data-path="../part4/监控--Prometheus告警篇（告警消息对接钉钉接口）.html">
            
                <a href="../part4/监控--Prometheus告警篇（告警消息对接钉钉接口）.html">
            
                    
                    4.3. Prometheus告警篇
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">Part 5-分布式存储Ceph</li>
        
        
    
        <li class="chapter " data-level="5.1" data-path="./">
            
                <a href="./">
            
                    
                    5. Ceph存储
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter active" data-level="5.1.1" data-path="Ceph集群生产环境安装部署.html">
            
                <a href="Ceph集群生产环境安装部署.html">
            
                    
                    5.1. Ceph部署篇
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.1.2" data-path="cephfs调优-性能测试-监控-常用命令.html">
            
                <a href="cephfs调优-性能测试-监控-常用命令.html">
            
                    
                    5.2. Ceph性能调优
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.1.3" data-path="分布式存储Cephfs使用.html">
            
                <a href="分布式存储Cephfs使用.html">
            
                    
                    5.3. Cephfs在k8s中使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.1.4" data-path="分布式存储Ceph-RBD使用.html">
            
                <a href="分布式存储Ceph-RBD使用.html">
            
                    
                    5.4. Ceph RBD在k8s中使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.1.5" data-path="Cephfs-CephRBD在k8s中的适用场景讨论及数据库性能压测.html">
            
                <a href="Cephfs-CephRBD在k8s中的适用场景讨论及数据库性能压测.html">
            
                    
                    5.5. Ceph在k8s中的综合场景应用及数据库OLTP性能压测
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">Part 6-微服务框架Istio</li>
        
        
    
        <li class="chapter " data-level="6.1" data-path="../part6/">
            
                <a href="../part6/">
            
                    
                    6. Istio微服务框架
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="6.1.1" data-path="../part6/微服务框架istio安装测试.html">
            
                <a href="../part6/微服务框架istio安装测试.html">
            
                    
                    6.1. istio安装测试
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.1.2" data-path="../part6/微服务框架istio流量策略控制.html">
            
                <a href="../part6/微服务框架istio流量策略控制.html">
            
                    
                    6.2. istio流量策略控制
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.1.3" data-path="../part6/微服务框架istio服务可视化与监控.html">
            
                <a href="../part6/微服务框架istio服务可视化与监控.html">
            
                    
                    6.3. istio服务可视化与监控
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.1.4" data-path="../part6/微服务--istio1.0抢鲜测试.html">
            
                <a href="../part6/微服务--istio1.0抢鲜测试.html">
            
                    
                    6.4. istio v1.0 抢鲜测试
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">Part 7-周边生态</li>
        
        
    
        <li class="chapter " data-level="7.1" data-path="../part7/">
            
                <a href="../part7/">
            
                    
                    7. 周边生态
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="7.1.1" data-path="../part7/Docker-registry仓库历史镜像批量清理.html">
            
                <a href="../part7/Docker-registry仓库历史镜像批量清理.html">
            
                    
                    7.1. Docker-registry历史镜像批量清理.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="7.1.2" data-path="../part7/企业级docker仓库Harbor在kubernetes上搭建使用.html">
            
                <a href="../part7/企业级docker仓库Harbor在kubernetes上搭建使用.html">
            
                    
                    7.2. Harbor部署使用
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">Part 8-问题记录</li>
        
        
    
        <li class="chapter " data-level="8.1" data-path="../part8/">
            
                <a href="../part8/">
            
                    
                    8. 问题记录
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="8.1.1" data-path="../part8/Kubernetes部署问题记录.html">
            
                <a href="../part8/Kubernetes部署问题记录.html">
            
                    
                    8.1. 集群部署问题记录
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="8.1.2" data-path="../part8/Service-ipvs模式间断性TCP连接故障排查.html">
            
                <a href="../part8/Service-ipvs模式间断性TCP连接故障排查.html">
            
                    
                    8.2. Service ipvs模式间断性TCP连接故障排查
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="8.1.3" data-path="../part8/kubeadm证书-etcd证书过期紧急处理.html">
            
                <a href="../part8/kubeadm证书-etcd证书过期紧急处理.html">
            
                    
                    8.3. kubeadm证书-etcd证书过期紧急处理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="8.1.4" data-path="../part8/Kubernetes-Pod无法终结问题排查.html">
            
                <a href="../part8/Kubernetes-Pod无法终结问题排查.html">
            
                    
                    8.4. Kubernetes-Pod无法终结问题排查
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >5.1. Ceph部署篇</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h2 id=""><a name="" class="plugin-anchor" href="#"><i class="fa fa-link" aria-hidden="true"></i></a> </h2>
<h2 id="&#x524D;&#x8A00;"><a name="&#x524D;&#x8A00;" class="plugin-anchor" href="#&#x524D;&#x8A00;"><i class="fa fa-link" aria-hidden="true"></i></a>&#x524D;&#x8A00;</h2>
<p>ceph&#x7684;&#x7EC4;&#x4EF6;&#x4EE5;&#x53CA;&#x5DE5;&#x4F5C;&#x6D41;&#x7A0B;&#x975E;&#x5E38;&#x7684;&#x590D;&#x6742;,&#x662F;&#x4E00;&#x4E2A;&#x5E9E;&#x5927;&#x7684;&#x7CFB;&#x7EDF;,&#x5728;&#x5C1D;&#x8BD5;ceph&#x4E4B;&#x524D;&#x5C3D;&#x91CF;&#x591A;&#x67E5;&#x9605;&#x5B98;&#x65B9;&#x7684;&#x6587;&#x6863;,&#x7406;&#x89E3;ceph&#x7684;mon/osd/mds/pg/pool&#x7B49;&#x5404;&#x7EC4;&#x4EF6;/Unit&#x7684;&#x534F;&#x540C;&#x5DE5;&#x4F5C;&#x65B9;&#x5F0F;
<a href="http://docs.ceph.com/docs/master/" target="_blank"><strong>Ceph&#x5B98;&#x65B9;&#x6587;&#x6863;</strong></a></p>
<h2 id="&#x4E00;&#x3001;&#x914D;&#x7F6E;&#x89C4;&#x5212;&#xFF1A;"><a name="&#x4E00;&#x3001;&#x914D;&#x7F6E;&#x89C4;&#x5212;&#xFF1A;" class="plugin-anchor" href="#&#x4E00;&#x3001;&#x914D;&#x7F6E;&#x89C4;&#x5212;&#xFF1A;"><i class="fa fa-link" aria-hidden="true"></i></a>&#x4E00;&#x3001;&#x914D;&#x7F6E;&#x89C4;&#x5212;&#xFF1A;</h2>
<p><img src="http://mycloudn.kokoerp.com/20180911115527618.jpg" alt="&#x8FD9;&#x91CC;&#x5199;&#x56FE;&#x7247;&#x63CF;&#x8FF0;"></p>
<h2 id="&#x4E8C;&#x3001;&#x90E8;&#x7F72;"><a name="&#x4E8C;&#x3001;&#x90E8;&#x7F72;" class="plugin-anchor" href="#&#x4E8C;&#x3001;&#x90E8;&#x7F72;"><i class="fa fa-link" aria-hidden="true"></i></a>&#x4E8C;&#x3001;&#x90E8;&#x7F72;</h2>
<p><strong>1. ntp-server&#x5F00;&#x542F;ntp&#x670D;&#x52A1;&#xFF1A;</strong></p>
<pre><code>apt-get install ntp ntpdate ntp-doc
systemctl enable ntp
systemctl start ntp
</code></pre><p><strong>2. ceph node</strong></p>
<p><strong>&#x4E09;&#x53F0;node&#x5168;&#x90E8;&#x6267;&#x884C;&#x5982;&#x4E0B;&#x64CD;&#x4F5C;&#xFF1A;</strong>
&#x78C1;&#x76D8;&#x5206;&#x533A;&#x89C4;&#x5212;&#x5982;&#x9876;&#x90E8;&#x8868;&#x683C;&#xFF0C;&#x6309;&#x7167;&#x89C4;&#x5212;&#x5199;&#x7684;&#x78C1;&#x76D8;&#x5212;&#x5206;&#x811A;&#x672C;&#xFF0C;&#x5206;&#x522B;&#x5728;3&#x53F0;node&#x4E0A;&#x6267;&#x884C;&#x811A;&#x672C;&#xFF1A;</p>
<pre><code># cat ~/parted.sh 

#!/bin/bash
set -e
if [ ! -x &quot;/usr/sbin/parted&quot; ]; then
echo &quot;This script requires /sbin/parted to run!&quot; &gt;&amp;2
exit 1
fi
DISKS=&quot;d e f g h i j k l m n o p&quot;
for i in ${DISKS}; do
  echo &quot;Creating partitions on /dev/sd${i} ...&quot;
  parted -a optimal --script /dev/sd${i} -- mktable gpt
  parted -a optimal --script /dev/sd${i} -- mkpart primary xfs 0% 100%
  sleep 1
  #echo &quot;Formatting /dev/sd${i}1 ...&quot;
  mkfs.xfs -f /dev/sd${i}1 &amp;
done

SSDS=&quot;b c&quot;
for i in ${SSDS}; do
  parted -s /dev/sd${i} mklabel gpt
  parted -s /dev/sd${i} mkpart primary 0% 10%
  parted -s /dev/sd${i} mkpart primary 11% 20%
  parted -s /dev/sd${i} mkpart primary 21% 30%
  parted -s /dev/sd${i} mkpart primary 31% 40%
  parted -s /dev/sd${i} mkpart primary 41% 50%
  parted -s /dev/sd${i} mkpart primary 51% 60%
  parted -s /dev/sd${i} mkpart primary 61% 70%
done

chown -R ceph:ceph /dev/sdb[1-7]
chown -R ceph:ceph /dev/sdc[1-7]
</code></pre><p>&#x6DFB;&#x52A0; /etc/hosts&#x89E3;&#x6790;&#xFF0C;&#x5E76;scp&#x5230;3&#x53F0;node&#x4E0A;:</p>
<pre><code>192.168.20.112  h020112
192.168.20.113  h020113
192.168.20.114  h020114
</code></pre><p> &#x5173;&#x95ED;&#x9632;&#x706B;&#x5899;&#x3001;selinux&#xFF0C;&#x6DFB;&#x52A0;&#x5B9A;&#x65F6;&#x540C;&#x6B65;&#x65F6;&#x95F4;&#x8BA1;&#x5212;&#x4EFB;&#x52A1;&#xFF1A;</p>
<pre><code> sed -i &apos;s/SELINUX=.*/SELINUX=disabled/&apos; /etc/selinux/config
 setenforce 0
 systemctl stop firewalld
 systemctl disable firewalld

 cat &gt;&gt;/etc/crontab&lt;&lt;EOF
 &#xD7; */1 * * * root ntpdate 192.168.9.28 &amp;&amp; --systohc
 EOF
</code></pre><pre><code>cd /etc/yum.repos.d
mv CentOS-Base.repo CentOS-Base.repo.bak
wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
yum -y install ntp ntpdate
yum -y install ceph
</code></pre><p><strong>&#x5728;node1(192.168.20.112)&#x4E0A;&#x6267;&#x884C;:</strong></p>
<pre><code>wget https://download.ceph.com/rpm-kraken/el7/noarch/ceph-deploy-1.5.37-0.noarch.rpm
yum -y install ceph-deploy-1.5.37-0.noarch.rpm

# &#x521B;&#x5EFA;&#x79D8;&#x94A5;&#xFF0C;&#x4F20;&#x9001;&#x5230;&#x5404;&#x8282;&#x70B9;&#xFF0C;&#x5B9E;&#x73B0;&#x65E0;&#x79D8;&#x94A5;&#x767B;&#x5F55;
ssh-keygen
ssh-copy-id h020112
ssh-copy-id h020113
ssh-copy-id h020114

# &#x65B0;&#x5EFA;&#x96C6;&#x7FA4;&#xFF0C;&#x751F;&#x6210;&#x914D;&#x7F6E;&#x6587;&#x4EF6;
mkdir ceph-cluster &amp;&amp; cd ceph-cluster
ceph-deploy new h020112 h020113 h020114

## &#x4FEE;&#x6539;&#x9ED8;&#x8BA4;&#x751F;&#x6210;&#x7684;ceph.conf&#xFF0C;&#x589E;&#x52A0;&#x5982;&#x4E0B;&#x914D;&#x7F6E;&#x6BB5;&#xFF1A;
# 80G&#x5FD7;&#x76D8;
osd_journal_size = 81920 
public_network= 192.168.20.0/24 
# &#x526F;&#x672C;pg&#x6570;&#x4E3A;2&#xFF0C;&#x9ED8;&#x8BA4;&#x4E3A;3&#xFF0C;&#x6700;&#x5C0F;&#x5DE5;&#x4F5C;size&#x4E3A;&#x9ED8;&#x8BA4;size - (&#x9ED8;&#x8BA4;size/2) 
osd pool default size = 2
# &#x5B98;&#x65B9;&#x5EFA;&#x8BAE;&#x5E73;&#x5747;&#x6BCF;&#x4E2A;osd &#x7684;pg&#x6570;&#x91CF;&#x4E0D;&#x5C0F;&#x4E8E;30&#xFF0C;&#x5373;pg num &gt; (osd_num) * 30 / 2(&#x526F;&#x672C;&#x6570;)
osd pool default pg num = 1024
osd pool default pgp num = 1024

# &#x4F20;&#x9001;ceph.conf
ceph-deploy --overwrite-conf config push h020112 h020113 h020114

# &#x82E5;&#x6709;RuntimeError: bootstrap-mds keyring not found; run &apos;gatherkeys&apos;&#x62A5;&#x9519;&#xFF0C;&#x5219;&#x6267;&#x884C;&#x5982;&#x4E0B;&#x547D;&#x4EE4;&#x4F20;&#x9001;key
ceph-deploy gatherkeys yh020112 h020113 h020114

# &#x521D;&#x59CB;&#x5316;mon&#x8282;&#x70B9;
ceph-deploy mon create-initial
ceph -s # &#x67E5;&#x770B;mon&#x662F;&#x5426;&#x6DFB;&#x52A0;&#x6210;&#x529F;

# ceph &#x96C6;&#x7FA4;&#x52A0;&#x5165;OSD
cd /etc/ceph # &#x4E00;&#x5B9A;&#x8981;&#x8FDB;&#x5165;&#x8FD9;&#x4E2A;&#x76EE;&#x5F55;&#x4E0B;

# &#x6267;&#x884C;&#x5982;&#x4E0B;&#x811A;&#x672C;&#xFF0C;&#x5FD7;&#x76D8;&#x548C;&#x6570;&#x636E;&#x76D8;&#x7684;&#x5BF9;&#x5E94;&#x5173;&#x7CFB;&#x8981;&#x518D;&#x4E09;&#x786E;&#x8BA4;
[root@h20112 ceph]# cat add_osd.sh 
#!/bin/bash

for ip in $(cat ~/ceph-cluster/cephosd.txt)  
do
echo ----$ip-----------;
ceph-deploy --overwrite-conf osd prepare $ip:sdd1:/dev/sdb1 $ip:sde1:/dev/sdb2 $ip:sdf1:/dev/sdb3 $ip:sdg1:/dev/sdb4  $ip:sdh1:/dev/sdb5  $ip:sdi1:/dev/sdb6  \
   $ip:sdj1:/dev/sdc1 $ip:sdk1:/dev/sdc2 $ip:sdl1:/dev/sdc3 $ip:sdm1:/dev/sdc4  $ip:sdn1:/dev/sdc5  $ip:sdo1:/dev/sdc6  $ip:sdp1:/dev/sdc7
done


for ip in $(cat ~/ceph-cluster/cephosd.txt)
do
echo ----$ip-----------;
ceph-deploy osd activate $ip:sdd1:/dev/sdb1 $ip:sde1:/dev/sdb2 $ip:sdf1:/dev/sdb3 $ip:sdg1:/dev/sdb4  $ip:sdh1:/dev/sdb5  $ip:sdi1:/dev/sdb6  \
   $ip:sdj1:/dev/sdc1 $ip:sdk1:/dev/sdc2 $ip:sdl1:/dev/sdc3 $ip:sdm1:/dev/sdc4  $ip:sdn1:/dev/sdc5  $ip:sdo1:/dev/sdc6  $ip:sdp1:/dev/sdc7
done
</code></pre><p>&#x67E5;&#x770B;&#x7ED3;&#x679C;&#xFF1A;</p>
<pre><code>[root@h20112 ceph]# ceph osd tree
ID WEIGHT   TYPE NAME           UP/DOWN REWEIGHT PRIMARY-AFFINITY 
-1 34.04288 root default                                          
-2 11.34763     host h020112                                   
 0  0.87289         osd.0            up  1.00000          1.00000 
 3  0.87289         osd.3            up  1.00000          1.00000 
 4  0.87289         osd.4            up  1.00000          1.00000 
 5  0.87289         osd.5            up  1.00000          1.00000 
 6  0.87289         osd.6            up  1.00000          1.00000 
 7  0.87289         osd.7            up  1.00000          1.00000 
 8  0.87289         osd.8            up  1.00000          1.00000 
 9  0.87289         osd.9            up  1.00000          1.00000 
10  0.87289         osd.10           up  1.00000          1.00000 
11  0.87289         osd.11           up  1.00000          1.00000 
12  0.87289         osd.12           up  1.00000          1.00000 
13  0.87289         osd.13           up  1.00000          1.00000 
14  0.87289         osd.14           up  1.00000          1.00000 
-3 11.34763     host h020113                                   
 1  0.87289         osd.1            up  1.00000          1.00000 
15  0.87289         osd.15           up  1.00000          1.00000 
16  0.87289         osd.16           up  1.00000          1.00000 
17  0.87289         osd.17           up  1.00000          1.00000 
18  0.87289         osd.18           up  1.00000          1.00000 
19  0.87289         osd.19           up  1.00000          1.00000 
20  0.87289         osd.20           up  1.00000          1.00000 
21  0.87289         osd.21           up  1.00000          1.00000 
22  0.87289         osd.22           up  1.00000          1.00000 
23  0.87289         osd.23           up  1.00000          1.00000 
24  0.87289         osd.24           up  1.00000          1.00000 
25  0.87289         osd.25           up  1.00000          1.00000 
26  0.87289         osd.26           up  1.00000          1.00000 
-4 11.34763     host h020114                                   
 2  0.87289         osd.2            up  1.00000          1.00000 
27  0.87289         osd.27           up  1.00000          1.00000 
28  0.87289         osd.28           up  1.00000          1.00000 
29  0.87289         osd.29           up  1.00000          1.00000 
30  0.87289         osd.30           up  1.00000          1.00000 
31  0.87289         osd.31           up  1.00000          1.00000 
32  0.87289         osd.32           up  1.00000          1.00000 
33  0.87289         osd.33           up  1.00000          1.00000 
34  0.87289         osd.34           up  1.00000          1.00000 
35  0.87289         osd.35           up  1.00000          1.00000 
36  0.87289         osd.36           up  1.00000          1.00000 
37  0.87289         osd.37           up  1.00000          1.00000 
38  0.87289         osd.38           up  1.00000          1.00000 

[root@h20112 ceph]# ceph -s
    cluster 6661d89d-5895-4bcb-9b11-9400638afc85
     health HEALTH_OK
     monmap e1: 3 mons at {h020112=192.168.20.112:6789/0,h020113=192.168.20.113:6789/0,h020114=192.168.20.114:6789/0}
            election epoch 6, quorum 0,1,2 h020112,h020113,h020114
     osdmap e199: 39 osds: 39 up, 39 in
            flags sortbitwise,require_jewel_osds
      pgmap v497: 1024 pgs, 1 pools, 0 bytes data, 0 objects
            4385 MB used, 34854 GB / 34858 GB avail
                1024 active+clean

# &#x82E5;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x91CC;&#x6307;&#x5B9A;&#x7684;pg_num &#x548C; php_num&#x672A;&#x751F;&#x6548;&#xFF0C;&#x4F7F;&#x7528;&#x547D;&#x4EE4;&#x6307;&#x5B9A;&#xFF1A;
sudo ceph osd pool set rbd pg_num 1024
sudo ceph osd pool set rbd pgp_num 1024
</code></pre><h2 id="&#x81EA;&#x5B9A;&#x4E49;crush&#x5206;&#x5E03;&#x5F0F;&#x8C03;&#x5EA6;&#x89C4;&#x5219;&#xFF1A;"><a name="&#x81EA;&#x5B9A;&#x4E49;crush&#x5206;&#x5E03;&#x5F0F;&#x8C03;&#x5EA6;&#x89C4;&#x5219;&#xFF1A;" class="plugin-anchor" href="#&#x81EA;&#x5B9A;&#x4E49;crush&#x5206;&#x5E03;&#x5F0F;&#x8C03;&#x5EA6;&#x89C4;&#x5219;&#xFF1A;"><i class="fa fa-link" aria-hidden="true"></i></a>&#x81EA;&#x5B9A;&#x4E49;crush&#x5206;&#x5E03;&#x5F0F;&#x8C03;&#x5EA6;&#x89C4;&#x5219;&#xFF1A;</h2>
<p>ceph&#x4E00;&#x5171;&#x6709;&#x5982;&#x4E0B;&#x5C42;&#x7EA7;&#x7684;&#x7BA1;&#x7406;&#x5355;&#x4F4D;&#xFF0C;&#x4ECE;&#x4E0A;&#x5230;&#x4E0B;&#x5C42;&#x7EA7;&#x4F9D;&#x6B21;&#x63D0;&#x5347;&#xFF0C;&#x53EF;&#x4EE5;&#x7075;&#x6D3B;&#x5730;&#x6309;&#x7167;&#x7269;&#x7406;&#x7684;&#x903B;&#x8F91;&#x7C92;&#x5EA6;&#xFF0C;&#x5C06;osd&#x5173;&#x8054;&#x5230;&#x4E0D;&#x540C;&#x7684;&#x4E3B;&#x673A;&#x3001;&#x673A;&#x4F4D;&#x3001;&#x673A;&#x67B6;&#x3001;pdu&#x3001;&#x673A;&#x623F;&#x3001;&#x533A;&#x57DF;&#x7B49;&#x7BA1;&#x7406;&#x5355;&#x4F4D;&#xFF0C;&#x6BCF;&#x4E00;&#x5C42;&#x7EA7;&#x7684;&#x6574;&#x4F53;&#x6743;&#x91CD;&#x503C;&#x7B49;&#x4E8E;&#x8BE5;&#x5C42;&#x7EA7;&#x4E0B;&#x6240;&#x6709;OSD&#x7684;&#x6743;&#x91CD;&#x4E4B;&#x548C;&#x3002;</p>
<pre><code>type 0 osd
type 1 host
type 2 chassis
type 3 rack
type 4 row
type 5 pdu
type 6 pod
type 7 room
type 8 datacenter
type 9 region
type 10 root
</code></pre><p><strong>&#x81EA;&#x5B9A;&#x4E49;crush&#x89C6;&#x56FE;:</strong>
&#x8FD9;&#x91CC;&#x53EA;&#x5199;&#x64CD;&#x4F5C;&#x65B9;&#x6CD5;&#xFF0C;&#x4E0D;&#x4F5C;&#x5B9E;&#x65BD;&#xFF0C;&#x672C;&#x6B21;&#x64CD;&#x4F5C;&#x7684;&#x73AF;&#x5883;&#x786C;&#x76D8;&#x6570;&#x76EE;&#x3001;&#x786C;&#x76D8;&#x89C4;&#x683C;&#x3001;&#x4E3B;&#x673A;&#x4F4D;&#x7F6E;&#x5747;&#x4E00;&#x81F4;&#xFF0C;&#x6682;&#x65F6;&#x4E0D;&#x4F5C;crush&#x8C03;&#x6574;</p>
<pre><code>ceph osd crush add-bucket hnc root #&#x6DFB;&#x52A0;root&#x5C42;&#x7EA7;&#x540D;&#x4E3A;hnc&#x7684;bucket
ceph osd crush add-bucket rack0 rack  #&#x6DFB;&#x52A0;rack&#x5C42;&#x7EA7;&#x540D;&#x4E3A;rack0&#x7684;bucket
ceph osd crush add-bucket rack1 rack  #&#x6DFB;&#x52A0;rack&#x5C42;&#x7EA7;&#x540D;&#x4E3A;rack1&#x7684;bucket
ceph osd crush add-bucket rack2 rack  #&#x6DFB;&#x52A0;rack&#x5C42;&#x7EA7;&#x540D;&#x4E3A;rack2&#x7684;bucket
ceph osd crush move rack0 root=hnc  #&#x5C06;rack0&#x79FB;&#x5165;hnc&#x4E4B;&#x4E0B;
ceph osd crush move rack0 root=hnc  #&#x5C06;rack1&#x79FB;&#x5165;hnc&#x4E4B;&#x4E0B;
ceph osd crush move rack0 root=hnc  #&#x5C06;rack2&#x79FB;&#x5165;hnc&#x4E4B;&#x4E0B;
ceph ods crush move h020112 rack=rack0  #&#x5C06;host h020112&#x79FB;&#x5165;rack0&#x5C42;&#x7EA7;&#x4E0B;
ceph ods crush move h020113 rack=rack1  #&#x5C06;host h020113&#x79FB;&#x5165;rack1&#x5C42;&#x7EA7;&#x4E0B;
ceph ods crush move h020114 rack=rack2  #&#x5C06;host h020114&#x79FB;&#x5165;rack2&#x5C42;&#x7EA7;&#x4E0B;

ceph osd getcrushmap -o map_old    &#x5BFC;&#x51FA;map
crushtool -d map_old -o map_old.txt  &#x8F6C;&#x5316;&#x6210;&#x53EF;&#x7F16;&#x8F91;&#x683C;&#x5F0F;

crushtool -c map_new.txt -o map_new  &#x8FD8;&#x539F;&#x4E3A;map
ceph osd setcrushmap -i map_new     &#x5C06;map&#x5BFC;&#x5165;ceph
</code></pre><p>&#x4FEE;&#x6539;&#x914D;&#x7F6E;&#x6587;&#x4EF6;,&#x9632;&#x6B62;ceph&#x81EA;&#x52A8;&#x66F4;&#x65B0;crushmap</p>
<pre><code>echo &#x2018;osd_crush_update_on_start = false&#x2018; &gt;&gt; /etc/ceph/ceph.conf
/etc/init.d/ceph restart
</code></pre><p>&#x4F7F;&#x7528;&#x5982;&#x4E0B;&#x6837;&#x4F8B;crash&#xFF08;map_new.txt&#xFF09;&#x914D;&#x7F6E;:</p>
<pre><code>--------------------------------------
# begin crush map
tunable choose_local_tries 0
tunable choose_local_fallback_tries 0
tunable choose_total_tries 50
tunable chooseleaf_descend_once 1
tunable straw_calc_version 1

# devices
device 0 osd.0
device 1 osd.1
device 2 osd.2
device 3 osd.3
device 4 osd.4
device 5 osd.5
device 6 osd.6
device 7 osd.7
device 8 osd.8
device 9 osd.9
device 10 osd.10
device 11 osd.11

# types
type 0 osd
type 1 host
type 2 chassis
type 3 rack
type 4 row
type 5 pdu
type 6 pod
type 7 room
type 8 datacenter
type 9 region
type 10 root

# buckets
root default {
    id -1        # do not change unnecessarily
    # weight 0.000
    alg straw
    hash 0    # rjenkins1
}

# &#x6743;&#x91CD;&#x503C;&#x4E00;&#x822C;&#x6839;&#x636E;&#x78C1;&#x76D8;&#x5BB9;&#x91CF;(&#x57FA;&#x6570;)&#x4E0E;&#x6027;&#x80FD;(&#x500D;&#x7387;)&#x8C03;&#x6574;&#xFF0C;&#x4F8B;&#x5982;&#x8BBE;&#x7F6E;1T&#x4E3A;1.00&#xFF0C;2T&#x4E3A;2.00&#xFF0C;hdd&#x500D;&#x6570;&#x4E3A;1&#xFF0C;ssd&#x500D;&#x6570;&#x4E3A;2
host h020112 {
    id -2        # do not change unnecessarily
    # weight 0.000
    alg straw
    hash 0    # rjenkins1
    item osd.0 weight 2.000
    item osd.1 weight 2.000
    item osd.2 weight 2.000
    item osd.3 weight 2.000
    # &#x9700;&#x5199;&#x51FA;&#x5168;&#x90E8;osd&#xFF0C;&#x8FD9;&#x91CC;&#x7701;&#x7565;&#x4E0D;&#x5199;&#x8FD9;&#x4E48;&#x591A;&#x4E86;
}
host h020113 {
    id -3        # do not change unnecessarily
    # weight 0.000
    alg straw
    hash 0    # rjenkins1
    item osd.4 weight 2.000
    item osd.5 weight 2.000
    item osd.6 weight 2.000
    item osd.7 weight 2.000
}
host h020114 {
    id -4        # do not change unnecessarily
    # weight 0.000
    alg straw
    hash 0    # rjenkins1
    item osd.8 weight  2.000 
    item osd.9 weight  2.000  
    item osd.10 weight 2.000  
    item osd.11 weight 2.000  
}
rack rack0 {
    id -6        # do not change unnecessarily
    # weight 0.000
    alg straw
    hash 0    # rjenkins1
    item h020112 weight 8.000
}
rack rack1 {
    id -7        # do not change unnecessarily
    # weight 0.000
    alg straw
    hash 0    # rjenkins1
    item h020113 weight 8.000
}
rack rack2 {
    id -8        # do not change unnecessarily
    # weight 0.000
    alg straw
    hash 0    # rjenkins1
    item h020114 weight 8.000
}
root hnc {
    id -5        # do not change unnecessarily
    # weight 0.000
    alg straw
    hash 0    # rjenkins1
    item rack0 weight 8.000
    item rack1 weight 8.000
    item rack2 weight 8.000
}

# rules
rule replicated_ruleset {                         #&#x89C4;&#x5219;&#x96C6;&#x7684;&#x547D;&#x540D;&#xFF0C;&#x521B;&#x5EFA;pool&#x65F6;&#x53EF;&#x4EE5;&#x6307;&#x5B9A;rule&#x96C6;
    ruleset 0                                     #rules&#x96C6;&#x7684;&#x7F16;&#x53F7;&#xFF0C;&#x987A;&#x5E8F;&#x7F16;&#x5373;&#x53EF;
    type replicated                               #&#x5B9A;&#x4E49;pool&#x7C7B;&#x578B;&#x4E3A;replicated(&#x8FD8;&#x6709;esurecode&#x6A21;&#x5F0F;)
    min_size 1                                    #pool&#x4E2D;&#x6700;&#x5C0F;&#x6307;&#x5B9A;&#x7684;&#x526F;&#x672C;&#x6570;&#x91CF;&#x4E0D;&#x80FD;&#x5C0F;1
    max_size 10                                   #pool&#x4E2D;&#x6700;&#x5927;&#x6307;&#x5B9A;&#x7684;&#x526F;&#x672C;&#x6570;&#x91CF;&#x4E0D;&#x80FD;&#x5927;&#x4E8E;10
    step take hnc                             #&#x5B9A;&#x4E49;pg&#x67E5;&#x627E;&#x526F;&#x672C;&#x7684;&#x5165;&#x53E3;&#x70B9;
    step chooseleaf firstn 0 type rack            #&#x9009;&#x53F6;&#x5B50;&#x8282;&#x70B9;&#x3001;&#x6DF1;&#x5EA6;&#x4F18;&#x5148;&#x3001;&#x9694;&#x79BB;rack
    step emit
}
# end crush map
</code></pre><p>&#x5C06;&#x4FEE;&#x6539;&#x540E;&#x7684;crushmap&#x7F16;&#x8BD1;&#x5E76;&#x4E14;&#x6CE8;&#x5165;&#x96C6;&#x7FA4;&#x4E2D;</p>
<pre><code>crushtool -c map_new.txt -o map_new
ceph osd setcrushmap -i map_new
ceph osd tree
ceph osd crush rm default  # &#x5220;&#x9664;&#x9ED8;&#x8BA4;crush map
systemctl stop ceph\*.service ceph\*.target  #&#x5173;&#x95ED;&#x6240;&#x6709;&#x670D;&#x52A1;
systemctl start ceph.target   #&#x542F;&#x52A8;&#x670D;&#x52A1;
</code></pre>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="./" class="navigation navigation-prev " aria-label="Previous page: 5. Ceph存储">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="cephfs调优-性能测试-监控-常用命令.html" class="navigation navigation-next " aria-label="Next page: 5.2. Ceph性能调优">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"5.1. Ceph部署篇","date":"2018/09/11 15:34:00","tags":["Kubernetes","Ceph"],"level":"5.1.1","depth":2,"next":{"title":"5.2. Ceph性能调优","level":"5.1.2","depth":2,"path":"part5/cephfs调优-性能测试-监控-常用命令.md","ref":"./part5/cephfs调优-性能测试-监控-常用命令.md","articles":[]},"previous":{"title":"5. Ceph存储","level":"5.1","depth":1,"path":"part5/README.md","ref":"./part5/README.md","articles":[{"title":"5.1. Ceph部署篇","level":"5.1.1","depth":2,"path":"part5/Ceph集群生产环境安装部署.md","ref":"./part5/Ceph集群生产环境安装部署.md","articles":[]},{"title":"5.2. Ceph性能调优","level":"5.1.2","depth":2,"path":"part5/cephfs调优-性能测试-监控-常用命令.md","ref":"./part5/cephfs调优-性能测试-监控-常用命令.md","articles":[]},{"title":"5.3. Cephfs在k8s中使用","level":"5.1.3","depth":2,"path":"part5/分布式存储Cephfs使用.md","ref":"./part5/分布式存储Cephfs使用.md","articles":[]},{"title":"5.4. Ceph RBD在k8s中使用","level":"5.1.4","depth":2,"path":"part5/分布式存储Ceph-RBD使用.md","ref":"./part5/分布式存储Ceph-RBD使用.md","articles":[]},{"title":"5.5. Ceph在k8s中的综合场景应用及数据库OLTP性能压测","level":"5.1.5","depth":2,"path":"part5/Cephfs-CephRBD在k8s中的适用场景讨论及数据库性能压测.md","ref":"./part5/Cephfs-CephRBD在k8s中的适用场景讨论及数据库性能压测.md","articles":[]}]},"dir":"ltr"},"config":{"plugins":["-sharing","anchors","github","expandable-chapters","splitter","back-to-top-button"],"styles":{"website":"./styles/website.css"},"pluginsConfig":{"github":{"url":"https://github.com/yinwenqin/kubeSourceCodeNote"},"splitter":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"back-to-top-button":{},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"anchors":{},"expandable-chapters":{}},"theme":"default","author":"ywq","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"Kubernetes生态圈使用","language":"zh-hans","links":{},"gitbook":"3.2.3","description":""},"file":{"path":"part5/Ceph集群生产环境安装部署.md","mtime":"2019-11-21T07:58:03.017Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-12-18T06:58:38.963Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

